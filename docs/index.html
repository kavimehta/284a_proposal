<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"></html>
<head>
<style>
    div.padded {
      padding-top: 0px;
      padding-right: 100px;
      padding-bottom: 0.25in;
      padding-left: 100px;
    }
    table {
      font-family: arial, sans-serif;
      border-collapse: collapse;
      width: 100%;
    }

    td, th {
      border: 1px solid #dddddd;
      text-align: left;
      padding: 8px;
    }

    tr:nth-child(even) {
      background-color: #dddddd;
    }
    html, body {
      font-family: "ff-meta-web-pro", sans-serif;
      text-rendering: optimizeLegibility;
      font-size: 100%;
      line-height: 26px;
      background: #f6efe5;
      background-size: 60%;
      color: #0d2c40;
    }
    a {
      color: #0d2c40;
      text-decoration: none;
      border-bottom: 1px solid #0d2c40;
      -webkit-transition: all 0.2s ease-out;
      -moz-transition: all 0.2s ease-out;
      -o-transition: all 0.2s ease-out;
      -ms-transition: all 0.2s ease-out;
      transition: all 0.2s ease-out;
    }
    a:hover {
      color: rgba(0, 0, 0, 0.4);
      border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    }
</style>
<title>CS 284a: Final Project Proposal</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="style.css" media="screen" />
</head>
<body>
<br />
<center>
<h1>CS 284a: Final Project Proposal: Filling Incomplete Sections in Point Clouds with GANs</h1>
</center>

<h2>Team</h2>
<p>Kavi Mehta, 25040386</p> <p>Jack Sullivan, 25195800</p> <p>David Tseng, 25291067</p>

<h2>Summary</h2>
<p>

We are trying to solve the problem of filling in incomplete segments of 3D point clouds using machine learning (GANs) in order to produce more accurate and high quality polygon meshes after remeshing. We are focusing on optimizing and evaluating for one class of Shapenet objects. To evaluate success, we would qualitatively compare the completeness and quality of the polygon meshes of the incomplete point cloud objects vs the reconstructed point cloud objects.

</p>

<h2>Problem Description</h2>
<p>
Point clouds have become increasingly popular data structures for representing 3D geometric objects and are used by many applications such as 3D scanners. These point clouds are usually converted into graphical polygon meshes that would be used in other applications such as animation. The problem is that the hardware that calculates the initial point cloud may be faulty, leading to more sparse point clouds or point clouds with missing segments all together. The errors in these incomplete point clouds will then propagate to produce inaccurate polygon meshes. In addition, we need an automated way of filling in the gaps of these point clouds. There have been recent solutions using heuristic-based methods and deep learning to resolve uniformly sparse point clouds, but the problem of missing segments (such as a whole leg of a chair missing) using GANs remains an open, unsolved problem. To solve this problem, we will take an incomplete point cloud, pass it through a pre-trained encoder network, then a generator network, and finally a pre-trained decoder network to produce the completed point cloud. We then remesh the completed point cloud using MeshLab. The discriminator will be used to distinguish between the output of the generator and the output of a complete point cloud encoded via the pre-trained encoder network.

<br>
</p>

<h2>Goals and Deliverables</h2>

<h3>What We Plan to Deliver</h3>

<h4>Overview</h4>
<p>
We plan to create a pipeline that accepts as input point cloud data and outputs a complete mesh. The point cloud data will have a missing chunk of the desired object, but the resulting mesh should have this filled in. Specifically, this involves two discrete steps: 1) training a GAN and using its generator to determine the missing chunk and add the necessary points to resolve it, and 2) using a point cloud to mesh converter. We aim to focus on step 1 and use an existing implementation of step 2 since solutions for this already exist in industry.

<br>
We plan on focusing on and optimizing for one class of objects (such as Shapenet chairs) and focus on expanding to multiple classes of objects if time permits. To generate a point cloud, we will use meshes from a single Shapenet category, and sample points proportionally to the area of each face. To generate an incomplete mesh, we will use K-means clustering to cluster the points, and remove a cluster. This will result in removing a section of the mesh (such as the leg of a chair). This incomplete mesh will be passed through a pre-trained encoder network, then a generator network, and finally a pre-trained decoder network to produce the completed point cloud. MeshLab will be used to remesh it into a polygon mesh.
</p>

<h4>What images will we create?</h4>
<p>
  We will be displaying the following images for comparison. A view of incomplete point clouds, a view of the
  reconstructed point clouds, the polygon mesh generated from the incomplete point clouds, and the polygon mesh generated from
  the completed/generated point clouds. In this comparison, we will highlight how the initial data lacked a significant part of the object and that our program was able to create the mesh successfully.
</p>

<h4>How will we measure the success of our system?</h4>
<p>
  To evaluate success, we will rely on visual accuracy:  either the mesh is complete or it is not.
  For example, we will test on a chair that has legs missing, or
  a bottle with a missing top. To quantitatively
  measure the performance of our GAN, we will use the Earth Mover's Distance between the
  generated point cloud and the original ground truth Shapenet point cloud. Smaller EMD would correspond to
  better performance.

</p>

<h4>What questions will our analysis answer?</h4>
<p>
  This analysis would answer whether it is possible for Generative Adversarial Networks
  to infer a 3D point cloud given incomplete information. Our analysis will explain why existing mesh generation methods fail in this edge case, and describe how we use GANs to successfully resolve this problem. We will connect our results with other papers that have worked in a similar space, and describe how the methods  could be combined to create a stronger meth generation tool.
</p>

<h3>What We Hope to Deliver: Reach Goals</h3>

<p>
  If time permits, we will expand our project to handle multiple categories of Shapenet by
  performing a more comprehensive training of our model. In an ideal mesh generation tool, we would be able to fill in missing chunks of objects even if those objects differ significantly from the training set.

</p>

<h2>Schedule</h2>

<table>
  <tr>
    <th>Date</th>
    <th>Week</th>
    <th>Goal by end of week</th>
    <th>Details</th>
  </tr>
  <tr>
    <td>April 9</td>
    <td>Week 1</td>
    <td>Project Proposal</td>
    <td>Finish proposal according to spec</td>
  </tr>
  <tr>
    <td>April 16</td>
    <td>Week 2</td>
    <td>Shape Net Baseline</td>
    <td>Download shape net images, remove chunks, visualize the point clouds and save example images; try using point cloud to mesh converter MeshLab</td>
  </tr>
  <tr>
    <td>April 23</td>
    <td>Week 3</td>
    <td>GANs baseline trained</td>
    <td>Set up GANs architecture and train it on our chosen point clouds; iterate on model</td>
  </tr>
  <tr>
    <td>April 30</td>
    <td>Week 4</td>
    <td>Milestone</td>
    <td>run some experiments using point clouds and GANs model; complete milestone according to spec</td>
  </tr>
  <tr>
    <td>May 9</td>
    <td>Week 5</td>
    <td>Final Presentations</td>
    <td>run more experiments and curate images of completed examples; aggregate evaluation metrics; create presentation deck</td>
  </tr>
  <tr>
    <td>May 14</td>
    <td>Week 6</td>
    <td>Final Deliverables</td>
    <td>write final paper according to spec</td>
  </tr>
</table>

<h2>Resources</h2>
There have been related work in this field. Mehdi Mirza et al. proposed <a href="https://arxiv.org/pdf/1411.1784.pdf">Conditional GANs </a>, which are GANs that are conditioned on a specific input instead of just a Gaussian noise vector. Since we're filling in holes of an existing point cloud, this will be very important. For latent representation of point clouds, we'll be referring to <a href="https://arxiv.org/abs/1707.02392">work</a> by Achlioptas et. al. Other related work include <a href="https://arxiv.org/abs/1804.07723">work </a> on filling in holes in 2D images (inpainting), and non-deep <a href="https://www.researchgate.net/publication/221403700_Filling_Holes_in_Point_Clouds">methods </a> for filling in missing chunks in point clouds.

<br>
For the point cloud dataset, we'll take meshes from <a href="https://www.shapenet.org/">Shapenet </a> and convert them to point clouds. To remesh point clouds into meshes, we will use the remeshing feature in MeshLab.
<br>

We will be using Numpy arrays to represent the point clouds, and Tensorflow to construct the Generative Adversarial Network. In order to train the GAN, we'll most likely be using AWS or OCF (if available). We may be starting off with https://github.com/optas/latent_3d_points to learn a latent representation of the point clouds, but will be modifying it in order to fit our new problem statement.


<!-- <a href="https://arxiv.org/pdf/1810.05795.pdf?fbclid=IwAR2CqAciKhIEmGoPHQYNksGUsyX54ArPPzOyy8urY2kHA6sPIAtP2rTs68w">Point Cloud GAN</a>
<a href="https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F221403700_Filling_Holes_in_Point_Clouds%3Ffbclid%3DIwAR2tQjXOpIkfp1DC9Ot5X4UgVZLWWovCe_WIpjdAg6dlR4hTP6GISMkHDgI&h=AT2MCu3jjvZFtnITcYAhBpMqFOxdxKUbs54lHlrL20Zvi9lVd3ZiepoL4WXHTKMy_ZSlcB-NSJOs-M2NjdslfnOwDDWtOKZ72DHDnsizeA5HCrhgSqdmeRlHDOURhX9jyYaKAsW4YNmF6Eg8dvsPEDGi">Filling Holes in Point Clouds</a>
<a href="/">2D Image Reconstruction using GANs</a> -->

</body>
