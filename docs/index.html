<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"></html>
<head>
<style>  
    div.padded {  
      padding-top: 0px;  
      padding-right: 100px;  
      padding-bottom: 0.25in;  
      padding-left: 100px;  
    }
    table {
      font-family: arial, sans-serif;
      border-collapse: collapse;
      width: 100%;
    }

    td, th {
      border: 1px solid #dddddd;
      text-align: left;
      padding: 8px;
    }

    tr:nth-child(even) {
      background-color: #dddddd;
    }
    html, body {
      font-family: "ff-meta-web-pro", sans-serif;
      text-rendering: optimizeLegibility;
      font-size: 100%;
      line-height: 26px;
      background: #f6efe5;
      background-size: 60%;
      color: #0d2c40;
    }
    a {
      color: #0d2c40;
      text-decoration: none;
      border-bottom: 1px solid #0d2c40;
      -webkit-transition: all 0.2s ease-out;
      -moz-transition: all 0.2s ease-out;
      -o-transition: all 0.2s ease-out;
      -ms-transition: all 0.2s ease-out;
      transition: all 0.2s ease-out;
    }
    a:hover {
      color: rgba(0, 0, 0, 0.4);
      border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    }
</style> 
<title>CS 284a: Final Project Proposal</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="style.css" media="screen" />
</head>
<body>
<br />
<center>
<h1>CS 284a: Final Project Proposal</h1>
</center>
<h2>Title</h2>
<p>Filling Incomplete Sections in Point Clouds with GANs</p>

<h2>Team</h2>
<p>Kavi Mehta, 25040386</p> <p>Jack Sullivan, 25195800</p> <p>David Tseng, 25291067</p>

<h2>Summary</h2>
<p>

We are trying to solve the problem of filling in incomplete segments of 3D point clouds using machine learning (GANs) in order to produce more accurate and high quality polygon meshes. We propose to solve the adjacent problem of filling in large incomplete segments (such as an entire chair leg) with similar machine learning tools that have been used to solve the incomplete images problem: GANs.

</p>

<h2>Problem Description</h2>
<p>
Point clouds have become increasingly popular data structures for representing 3D geometric objects and are used by many applications such as 3D scanners. These point clouds can then be converted into graphical polygon meshes that can be further modified. The problem is that the hardware that calculates the initial point cloud may be faulty, leading to more sparse point clouds or point clouds with missing segments all together. These incomplete point clouds will then propagate to produce inaccurate polygon meshes. In addition, we need an automated way of filling in the gaps of these point clouds. There have been recent solutions using heuristic-based methods and deep learning to resolve uniformly sparse point clouds, but the problem of missing segments (such as a whole leg of a chair missing) using GANs remains an open, unsolved problem. To solve this problem, we will take an incomplete point cloud, pass it through a pre-trained encoder network, then a generator network, and finally a pre-trained decoder network. The discriminator will be used to distinguish between the output of the generator and the output of a complete point cloud encoded via the pre-trained encoder network. 

<br>
</p>

<h2>Goals and Deliverables</h2>

<h3>What We Plan to Deliver</h3>

<h4>Overview</h4>
<p>
We plan to create a pipeline that accepts as input point cloud data and outputs a complete mesh. The point cloud data will have a missing chunk of the desired object, but the resulting mesh should have this filled in. Specifically, this involves two discrete steps: 1) training a GAN and using its generator to determine the missing chunk and add the necessary points to resolve it, and 2) using a point cloud to mesh converter. We aim to focus on step 1 and use an existing implementation of step 2 since that problem has already been thoroughly covered.

In terms of what we plan to deliver, we plan on focusing on and optimizing for one class of objects (such as chairs) and focus on expanding to multiple classes of objects if time permits. The images we will create are the incomplete point clouds, the reconstructed point clouds, and the polygon meshes generated from both kinds of point clouds. To evaluate success, we would qualitatively compare the completeness and quality of the polygon meshes of the incomplete point cloud objects vs the reconstructed point cloud objects. The images we will create are the reconstructed point clouds and the polygon meshes generated from the point clouds.
</p>

<h4>What images will we create?</h4>
<p>
  Our results will be images with the complete mesh compared to the original point cloud. In this comparison, we will highlight how the initial data lacked a significant part of the object and that our program was able to create the mesh successfully. Intermediate objects include the complete (filled in) point cloud and the mesh based on the incomplete point cloud.
</p>

<h4>How will we measure the success of our system?</h4>
<p>
  Our success metric is very simple: either the mesh is complete or it is not. We will evaluate our performance using the binary metric, 
  and intentionally choose input data where the desired result is obvious. For example, we will test on a chair that has legs missing, or 
  a bottle with a missing top.
</p>

<h4>What questions will our analysis answer?</h4>
<p>
  Our analysis will explain why existing mesh generation methods fail in this edge case, and describe how we use GANs to successfully
  resolve this problem. We will connect our results with other papers that have worked in a similar space, and describe how the methods 
  could be combined to create a stronger meth generation tool.
</p>

<h3>What We Hope to Deliver</h3>

<h4>Areas to go further...</h4>
<p>
  If time permits, we will expand our project to handle more objects by performing a more comprehensive training of our model. In an ideal 
  mesh generation tool, we would be able to fill in missing chunks of objects even if those objects differ significantly from the training set.
</p>

<h2>Schedule</h2>

<table>
  <tr>
    <th>Date</th>
    <th>Week</th>
    <th>Goal by end of week</th>
    <th>Details</th>
  </tr>
  <tr>
    <td>April 9</td>
    <td>Week 1</td>
    <td>Project Proposal</td>
    <td>finish proposal according to spec</td>
  </tr>
  <tr>
    <td>April 16</td>
    <td>Week 2</td>
    <td>Shape Net Baseline</td>
    <td>download shape net images, remove chunks, visualize the point clouds and save example images; try using point cloud to mesh converter MeshLab</td>
  </tr>
  <tr>
    <td>April 23</td>
    <td>Week 3</td>
    <td>GANs baseline trained</td>
    <td>set up GANs architecture and train it on our chosen point clouds; iterate on model</td>
  </tr>
  <tr>
    <td>April 30</td>
    <td>Week 4</td>
    <td>Milestone</td>
    <td>run some experiments using point clouds and GANs model; complete milestone according to spec</td>
  </tr>
  <tr>
    <td>May 9</td>
    <td>Week 5</td>
    <td>Final Presentations</td>
    <td>run more experiments and curate images of completed examples; aggregate evaluation metrics; create presentation deck</td>
  </tr>
  <tr>
    <td>May 14</td>
    <td>Week 6</td>
    <td>Final Deliverables</td>
    <td>write final paper according to spec</td>
  </tr>
</table>

<h2>Resources</h2>
There have been related work in this field. Mehdi Mirza et al. proposed <a href="https://arxiv.org/pdf/1411.1784.pdf">Conditional GANs </a>, which are GANs that are conditioned on a specific input instead of just a Gaussian noise vector. Since we're filling in holes of an existing point cloud, this will be very important. For latent representation of point clouds, we'll be referring to <a href="https://arxiv.org/abs/1707.02392">work</a> by Achlioptas et. al. Other related work include <a href="https://arxiv.org/abs/1804.07723">work </a> on filling in holes in 2D images (inpainting), and non-deep <a href="https://www.researchgate.net/publication/221403700_Filling_Holes_in_Point_Clouds">methods </a> for filling in missing chunks in point clouds. 

<br>
For the point cloud dataset, we'll take meshes from <a href="https://www.shapenet.org/">Shapenet </a> and convert them to point clouds. 
<br>

We will be using Numpy arrays to represent the point clouds, and Tensorflow to construct the Generative Adversarial Network. In order to train the GAN, we'll most likely be using AWS or OCF (if available). We may be starting off with https://github.com/optas/latent_3d_points to learn a latent representation of the point clouds, but will be modifying it in order to fit our new problem statement. 


<!-- <a href="https://arxiv.org/pdf/1810.05795.pdf?fbclid=IwAR2CqAciKhIEmGoPHQYNksGUsyX54ArPPzOyy8urY2kHA6sPIAtP2rTs68w">Point Cloud GAN</a>
<a href="https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F221403700_Filling_Holes_in_Point_Clouds%3Ffbclid%3DIwAR2tQjXOpIkfp1DC9Ot5X4UgVZLWWovCe_WIpjdAg6dlR4hTP6GISMkHDgI&h=AT2MCu3jjvZFtnITcYAhBpMqFOxdxKUbs54lHlrL20Zvi9lVd3ZiepoL4WXHTKMy_ZSlcB-NSJOs-M2NjdslfnOwDDWtOKZ72DHDnsizeA5HCrhgSqdmeRlHDOURhX9jyYaKAsW4YNmF6Eg8dvsPEDGi">Filling Holes in Point Clouds</a>
<a href="/">2D Image Reconstruction using GANs</a> -->

</body>

